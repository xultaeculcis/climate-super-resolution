adagrad:
  _target_: torch.optim.Adagrad
  lr: ${training.lr}
