# Paths to CRU-TS NetCDF files
ds_path: "datasets/download/cruts/extracted/cru_ts4.05.1901.2020.tmp.dat.nc"

# Paths to tiff data dirs
data_dir: "datasets/pre-processed/cruts/full-res"
original_full_res_cruts_data_path: "datasets/pre-processed/cruts/full-res"
inference_out_path: "datasets/inference/europe-extent/cruts/tiff"

# Europe extent dirs
tiff_dir: "datasets/pre-processed/cruts/europe-extent"
extent_out_path_sr: "datasets/inference/europe-extent/cruts/tiff"
extent_out_path_sr_nc: "datasets/inference/europe-extent/cruts/nc"

# Pretrained models
pretrained_model: ???

# Misc
use_netcdf_datasets: False
temp_only: True # Use model trained on combined temp data? Or models trained on individual files.
generator_name: ???

# Dataset stuff
elevation_file: "datasets/pre-processed/world-clim/europe-extent/elev/wc2.1_2.5m_elev.tif"
land_mask_file: "datasets/pre-processed/world-clim/europe-extent/tmax/wc2.1_2.5m_tmax_1961-01.tif"
use_elevation: True
use_mask: True
use_global_min_max: True
cruts_variable: "tmp" # Select null if you want to run in a loop for all variables
scaling_factor: 4
normalize: True
normalization_range: [-1.0, 1.0]
min_max_lookup: "datasets/pre-processed/feather/statistics_min_max.feather"
zscore_lookup: "datasets/pre-processed/feather/statistics_zscore.feather"

# Run steps
run_inference: True
extract_polygon_extent: True
to_netcdf: True
