{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "athletic-singles",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-18T16:30:47.860810Z",
     "iopub.status.busy": "2021-03-18T16:30:47.860549Z",
     "iopub.status.idle": "2021-03-18T16:30:47.866380Z",
     "shell.execute_reply": "2021-03-18T16:30:47.865771Z",
     "shell.execute_reply.started": "2021-03-18T16:30:47.860782Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from rio_tiler.io import COGReader\n",
    "from rio_tiler.models import ImageData, ImageStatistics, Info, Metadata\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "processed-improvement",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-18T16:43:08.951166Z",
     "iopub.status.busy": "2021-03-18T16:43:08.950920Z",
     "iopub.status.idle": "2021-03-18T16:43:08.968277Z",
     "shell.execute_reply": "2021-03-18T16:43:08.967711Z",
     "shell.execute_reply.started": "2021-03-18T16:43:08.951140Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClimScaler:\n",
    "    \"\"\"\n",
    "    The custom Min-Max scaler for the climate dataset.\n",
    "\n",
    "    There are a couple of ways you can use this class. Similarly to `scikit-learn`'s `MinMaxScaler`\n",
    "    you can fit on a single `numpy` array and then do a transformation on other array.\n",
    "    Or you can run `fit_transform`, which will do both.\n",
    "\n",
    "    There are methods which work on a collection of files as well - will use `Dask` to distribute the workload.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.feature_range = (0.0, 1.0)\n",
    "        self.lower_bound, self.upper_bound = self.feature_range\n",
    "        self.nan_replacement = 0.0\n",
    "\n",
    "    def fit(self, fpaths: List[str]) -> None:\n",
    "        \"\"\"\n",
    "        Compute the minimum and maximum to be used for later scaling.\n",
    "\n",
    "        Args:\n",
    "            fpaths (List[str]): The list of paths to .tif files.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.fpaths = fpaths\n",
    "\n",
    "        def find_min_max(file_path: str) -> Tuple[float, float]:\n",
    "            \"\"\"\n",
    "            Find min and max value in the single file.\n",
    "\n",
    "            Args:\n",
    "                file_path (str): A path to a single file.\n",
    "\n",
    "            Returns (Tuple[float, float]): Tuple with min and max value.\n",
    "\n",
    "            \"\"\"\n",
    "            img = Image.open(file_path)\n",
    "            arr = np.array(img, dtype=np.float)\n",
    "            arr[arr == -32768] = np.nan\n",
    "            xmin = np.nanmin(arr)\n",
    "            xmax = np.nanmax(arr)\n",
    "\n",
    "            return xmin, xmax\n",
    "\n",
    "        c = Client(n_workers=8, threads_per_worker=1)\n",
    "\n",
    "        results = (\n",
    "            dask.bag.from_sequence(self.fpaths, npartitions=len(self.fpaths))\n",
    "            .map(find_min_max)\n",
    "            .compute()\n",
    "        )\n",
    "\n",
    "        c.close()\n",
    "\n",
    "        current_min = 9999\n",
    "        current_max = -9999\n",
    "\n",
    "        for xmin, xmax in results:\n",
    "            if current_min > xmin:\n",
    "                current_min = xmin\n",
    "            if current_max < xmax:\n",
    "                current_max = xmax\n",
    "\n",
    "        self.org_data_min_ = current_min\n",
    "        self.org_data_max_ = current_max\n",
    "        self.data_min_ = current_min - 1\n",
    "        self.data_max_ = current_max + 1\n",
    "        self.data_range_ = self.data_max_ - self.data_min_\n",
    "        self.scale_ = (self.upper_bound - self.lower_bound) / self.data_range_\n",
    "        self.min_ = self.lower_bound - self.data_min_ * self.scale_\n",
    "\n",
    "    def fit_single(self, X: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Compute the minimum and maximum to be used for later scaling.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): The numpy array with data\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        arr = X.astype(float)\n",
    "        arr[arr == -32768] = np.nan\n",
    "        xmin = np.nanmin(arr)\n",
    "        xmax = np.nanmax(arr)\n",
    "\n",
    "        self.org_data_min_ = xmin\n",
    "        self.org_data_max_ = xmax\n",
    "        self.data_min_ = xmin - 1\n",
    "        self.data_max_ = xmax + 1\n",
    "        self.data_range_ = self.data_max_ - self.data_min_\n",
    "        self.scale_ = (self.upper_bound - self.lower_bound) / self.data_range_\n",
    "        self.min_ = self.lower_bound - self.data_min_ * self.scale_\n",
    "\n",
    "    def transform_single(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Scale features of X according to feature_range.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): The array.\n",
    "\n",
    "        Returns (np.ndarray): The scaled array.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        X = X.astype(np.float32)\n",
    "        X[X == -32768.0] = np.nan\n",
    "        X_std = (X - self.data_min_) / (self.data_max_ - self.data_min_)\n",
    "        X_scaled = X_std * (self.upper_bound - self.lower_bound) + self.lower_bound\n",
    "        X_scaled[np.isnan(X_scaled)] = self.nan_replacement\n",
    "        return X_scaled\n",
    "\n",
    "    def fit_transform_single(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Fit to data, then transform it.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): The numpy array with data.\n",
    "\n",
    "        Returns (np.ndarray): The transformed data.\n",
    "\n",
    "        \"\"\"\n",
    "        self.fit_single(X)\n",
    "        return self.transform_single(X)\n",
    "\n",
    "    def transform(self, fpaths: List[str], out_dir: str) -> None:\n",
    "        \"\"\"\n",
    "        Scale features of files according to feature_range.\n",
    "\n",
    "        Args:\n",
    "            fpaths (List[str]): The file paths.\n",
    "            out_dir (str): The output directory.\n",
    "\n",
    "        \"\"\"\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        def transform_(\n",
    "            fpath: str,\n",
    "            out_dir: str,\n",
    "            min_val: float,\n",
    "            max_val: float,\n",
    "            lower: Optional[float] = 0.0,\n",
    "            upper: Optional[float] = 1.0,\n",
    "            nan_replacement: Optional[float] = 0.0,\n",
    "        ) -> None:\n",
    "            \"\"\"\n",
    "            Scale features of single file according to feature_range.\n",
    "\n",
    "            Args:\n",
    "                fpath (str): The file path.\n",
    "                out_dir (str): The output directory.\n",
    "                min_val (float): The min val.\n",
    "                max_val (float): The max val.\n",
    "                lower (Optional[float]): The lower bound of feature range.\n",
    "                upper (Optional[float]): The upper bound of feature range.\n",
    "                nan_replacement (Optional[float]): The value to use in order to replace NaNs.\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            im_name = os.path.basename(os.path.splitext(fpath)[0]) + \".tiff\"\n",
    "            if os.path.exists(im_name):\n",
    "                return\n",
    "            X = np.array(Image.open(fpath), dtype=np.float)\n",
    "            X[X == -32768.0] = np.nan\n",
    "            X_std = (X - min_val) / (max_val - min_val)\n",
    "            X_scaled = X_std * (upper - lower) + lower\n",
    "            X_scaled[np.isnan(X_scaled)] = nan_replacement\n",
    "\n",
    "            im = Image.fromarray(X_scaled)\n",
    "            im.save(os.path.join(out_dir, im_name))\n",
    "\n",
    "        c = Client(n_workers=8, threads_per_worker=1)\n",
    "\n",
    "        _ = (\n",
    "            dask.bag.from_sequence(fpaths, npartitions=len(fpaths))\n",
    "            .map(\n",
    "                transform_,\n",
    "                out_dir=out_dir,\n",
    "                min_val=self.data_min_,\n",
    "                max_val=self.data_max_,\n",
    "                lower=self.lower_bound,\n",
    "                upper=self.upper_bound,\n",
    "                nan_replacement=self.nan_replacement,\n",
    "            )\n",
    "            .compute()\n",
    "        )\n",
    "\n",
    "        c.close()\n",
    "\n",
    "    def fit_transform(self, fpaths: List[str], out_dir: str) -> None:\n",
    "        \"\"\"\n",
    "        Fit to data, then transform it.\n",
    "\n",
    "        Args:\n",
    "            fpaths (List[str]): The file paths.\n",
    "            out_dir (str): The output directory.\n",
    "\n",
    "        \"\"\"\n",
    "        self.fit(fpaths)\n",
    "        self.transform(fpaths, out_dir)\n",
    "\n",
    "    def inverse_transform(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Undo the scaling of X according to feature_range.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): The numpy array with data.\n",
    "\n",
    "        \"\"\"\n",
    "        X = X.copy()\n",
    "        X[X == 0.0] = np.nan\n",
    "        return X * (self.data_max_ - self.data_min_) + self.data_min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "minute-climb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-18T16:58:27.460038Z",
     "iopub.status.busy": "2021-03-18T16:58:27.459283Z",
     "iopub.status.idle": "2021-03-18T16:58:27.498432Z",
     "shell.execute_reply": "2021-03-18T16:58:27.497777Z",
     "shell.execute_reply.started": "2021-03-18T16:58:27.459841Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import rasterio as rio\n",
    "from rasterio import windows\n",
    "\n",
    "in_path = \"/media/xultaeculcis/2TB/datasets/wc/pre-processed/tmax/resized/1x/\"\n",
    "input_filename = \"wc2.1_2.5m_tmax_1961-01.tif\"\n",
    "outpath = \"./\"\n",
    "\n",
    "\n",
    "def get_tiles(ds, width=128, height=128):\n",
    "    ncols, nrows = ds.meta[\"width\"], ds.meta[\"height\"]\n",
    "    offsets = np.array(list(product(range(0, ncols, width), range(0, nrows, height))))\n",
    "    big_window = windows.Window(col_off=0, row_off=0, width=ncols, height=nrows)\n",
    "\n",
    "    for col_off, row_off in offsets:\n",
    "        leftover_w = ncols - col_off\n",
    "        leftover_h = nrows - row_off\n",
    "\n",
    "        if leftover_w < width:\n",
    "            col_off = ncols - width\n",
    "\n",
    "        if leftover_h < height:\n",
    "            row_off = nrows - height\n",
    "\n",
    "        window = windows.Window(\n",
    "            col_off=col_off, row_off=row_off, width=width, height=height\n",
    "        ).intersection(big_window)\n",
    "        transform = windows.transform(window, ds.transform)\n",
    "        yield window, transform\n",
    "\n",
    "\n",
    "def make_patches(file_path, outpath, tile_shape=(128, 128)):\n",
    "    with rio.open(file_path) as inds:\n",
    "        tile_width, tile_height = tile_shape\n",
    "        fname = os.path.basename(os.path.splitext(file_path)[0]) + \".{}.{}.tif\"\n",
    "\n",
    "        data = inds.read()\n",
    "        meta = inds.meta.copy()\n",
    "\n",
    "        scaler = ClimScaler()\n",
    "        scaler.fit_single(data)\n",
    "\n",
    "        for window, transform in get_tiles(inds):\n",
    "            meta[\"transform\"] = transform\n",
    "            meta[\"width\"], meta[\"height\"] = window.width, window.height\n",
    "            out_fp = os.path.join(\n",
    "                out_path, fname.format(int(window.col_off), int(window.row_off))\n",
    "            )\n",
    "            with rio.open(out_fp, \"w\", **meta) as outds:\n",
    "                sample = inds.read(window=window)\n",
    "                scaled = scaler.transform_single(sample)\n",
    "                outds.write(scaled)\n",
    "\n",
    "\n",
    "make_patches(os.path.join(in_path, input_filename), outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-trace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
