{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "from pre_processing.cruts_config import CRUTSConfig\n",
    "from rasterio.mask import mask\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1428/1428 [00:08<00:00, 160.09it/s]\n",
      "100%|██████████| 1428/1428 [00:23<00:00, 59.57it/s]\n",
      "100%|██████████| 1428/1428 [00:18<00:00, 77.07it/s]\n",
      "100%|██████████| 1428/1428 [00:18<00:00, 75.68it/s]\n"
     ]
    }
   ],
   "source": [
    "europe_bbox = ((-16, 84.25), (40.25, 32.875))\n",
    "left_upper = [-16, 84.25]\n",
    "left_lower = [-16, 32.875]\n",
    "right_upper = [40.25, 84.25]\n",
    "right_lower = [40.25, 32.875]\n",
    "inference_dir = \"/media/xultaeculcis/2TB/datasets/cruts/inference\"\n",
    "bbox = [\n",
    "    {\n",
    "        \"coordinates\": [[left_upper, right_upper, right_lower, left_lower, left_upper]],\n",
    "        \"type\": \"Polygon\",\n",
    "    }\n",
    "]\n",
    "out_path = \"/media/xultaeculcis/2TB/datasets/cruts/inference-europe-extent\"\n",
    "\n",
    "for var in CRUTSConfig.variables_cts:\n",
    "    files = sorted(glob(os.path.join(inference_dir, var, \"*.tif\")))\n",
    "    os.makedirs(os.path.join(out_path, var), exist_ok=True)\n",
    "    for fp in tqdm(files):\n",
    "        filename = os.path.basename(fp)\n",
    "\n",
    "        with rio.open(fp) as ds:\n",
    "            crop, transform = mask(ds, bbox, crop=True)\n",
    "            meta = ds.meta\n",
    "\n",
    "        meta.update(\n",
    "            {\n",
    "                \"driver\": \"GTiff\",\n",
    "                \"height\": crop.shape[1],\n",
    "                \"width\": crop.shape[2],\n",
    "                \"transform\": transform,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        with rio.open(os.path.join(out_path, var, filename), \"w\", **meta) as dest:\n",
    "            dest.write(crop)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1428/1428 [00:02<00:00, 479.79it/s]\n",
      "100%|██████████| 1428/1428 [00:08<00:00, 165.46it/s]\n",
      "100%|██████████| 1428/1428 [00:04<00:00, 314.23it/s]\n",
      "100%|██████████| 1428/1428 [00:03<00:00, 467.00it/s]\n"
     ]
    }
   ],
   "source": [
    "nc_out_path = \"/media/xultaeculcis/2TB/datasets/cruts/inference-europe-extent-nc\"\n",
    "os.makedirs(nc_out_path, exist_ok=True)\n",
    "\n",
    "var_to_variable = {\n",
    "    CRUTSConfig.pre: \"Precipitation\",\n",
    "    CRUTSConfig.tmn: \"Minimum Temperature\",\n",
    "    CRUTSConfig.tmp: \"Average Temperature\",\n",
    "    CRUTSConfig.tmx: \"Maximum Temperature\",\n",
    "}\n",
    "\n",
    "for var in CRUTSConfig.variables_cts:\n",
    "    das = []\n",
    "    fps = sorted(glob(os.path.join(out_path, var, \"*.tif\")))\n",
    "    timestamps = []\n",
    "    lat = None\n",
    "    lon = None\n",
    "    arrs = []\n",
    "    for fp in tqdm(fps):\n",
    "        filename = os.path.basename(fp)\n",
    "\n",
    "        splitted = filename.replace(\".tif\", \"\").split(\"-\")\n",
    "        timestamp = \"-\".join(splitted[-3:])\n",
    "        timestamps.append(timestamp)\n",
    "\n",
    "        da = xr.open_rasterio(fp).rename(var)\n",
    "        if lat is None:\n",
    "            lat = da.y.data\n",
    "        if lon is None:\n",
    "            lon = da.x.data\n",
    "        arr = da.data\n",
    "        arrs.append(arr)\n",
    "\n",
    "    var_data = np.concatenate(arrs, axis=0)\n",
    "    time = pd.to_datetime(timestamps)\n",
    "    ds = xr.Dataset(\n",
    "        {\n",
    "            var: ((\"time\", \"lat\", \"lon\"), var_data),\n",
    "        },\n",
    "        {\"time\": time, \"lon\": lon, \"lat\": lat},\n",
    "        {\n",
    "            \"Conventions\": \"CF-1.4\",\n",
    "            \"title\": f\"CRU TS4.04 {var_to_variable[var]}\",\n",
    "            \"source\": \"Neural-Downscaling approach.\",\n",
    "            \"extent\": \"Europe. Based on ETRS89.\",\n",
    "        },\n",
    "    )\n",
    "    ds.to_netcdf(\n",
    "        os.path.join(nc_out_path, f\"cru_ts4.04.nn.inference.1901.2019.{var}.dat.nc\")\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
