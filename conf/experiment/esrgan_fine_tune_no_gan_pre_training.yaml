# @package _global_
defaults:
  - /optimizers@optimizers.generator_optimizer: adamw
  - /optimizers@optimizers.discriminator_optimizer: adamw
  - /schedulers@schedulers.generator_scheduler: one_cycle_schedule
  - /schedulers@schedulers.discriminator_scheduler: one_cycle_schedule
  - override /task: gan_training
  - override /datamodule: super_resolution_data_module
  - override /training: default
  - override /generator: esrgan
  - override /discriminator: rfb_esrgan_discriminator
  - override /trainer: default

training:
  lr: 1e-4
  batch_size: 16
  validation_batch_size: 32
  generator_type: "esrgan"
  experiment_name: "esrgan-gan-fine-tuning-no-gan-pre-training"
  run_fit: True
  run_test_after_fit: True
  num_workers: 4
  model_weights: "outputs/runs/esrgan/2021-11-10/06-48-08/model_weights/esrgan-no-transforms_epoch=029_step=82709_hp_metric=0.46519.ckpt"

trainer:
  gpus: 1
  accumulate_grad_batches: 1
  benchmark: True
  precision: 16
  max_epochs: 30

datamodule:
  cfg:
    batch_size: ${training.batch_size}
    num_workers: ${training.num_workers}
    pin_memory: True
    data_path: "datasets"
    europe_extent: True
    world_clim_variable: "temp"
    resolutions:
      - "2.5m"
    generator_type: ${training.generator_type}
    scale_factor: 4
    seed: ${training.seed}
    normalization_method: "minmax"
    normalization_range: [ -1.0, 1.0 ]
    use_elevation: True
    use_mask: True
    use_global_min_max: False
    use_extra_data: False
    transforms:
      v_flip: False
      h_flip: False
      random_90_rotation: False
