{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "modern-measure",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-sport",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from typing import Tuple\n",
    "\n",
    "import dask.bag\n",
    "import datacube.utils.geometry as dcug\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import xarray\n",
    "from dask.diagnostics import ProgressBar\n",
    "from datacube.utils.cog import write_cog\n",
    "from distributed import Client\n",
    "from rasterio import Affine, MemoryFile\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "pbar = ProgressBar()\n",
    "pbar.register()\n",
    "\n",
    "\n",
    "data_dir = \"/media/xultaeculcis/2TB/datasets/cruts/original/\"\n",
    "\n",
    "tmn = \"tmn\"\n",
    "tmx = \"tmx\"\n",
    "tmp = \"tmp\"\n",
    "pre = \"pre\"\n",
    "\n",
    "variables = [\n",
    "    tmn,\n",
    "    tmx,\n",
    "    tmp,\n",
    "    pre,\n",
    "]\n",
    "\n",
    "variable_files = [f\"cru_ts4.04.1901.2019.{var}.dat.nc\" for var in variables]\n",
    "\n",
    "out_dir = \"/media/xultaeculcis/2TB/datasets/cruts/pre-processed/\"\n",
    "\n",
    "full_res_dir = \"full-res\"\n",
    "tiles_dir = \"tiles\"\n",
    "\n",
    "sub_dirs = [\n",
    "    full_res_dir,\n",
    "    tiles_dir,\n",
    "]\n",
    "\n",
    "# ensure sub-dirs exist\n",
    "for dir_name in sub_dirs:\n",
    "    for var in variables:\n",
    "        os.makedirs(os.path.join(out_dir, dir_name, var), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-circulation",
   "metadata": {},
   "source": [
    "# Convert CRU-TS To COG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-course",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def as_cog(var: str) -> None:\n",
    "    fp = f\"cru_ts4.04.1901.2019.{var}.dat.nc\"\n",
    "    file_path = os.path.join(data_dir, fp)\n",
    "    out_path = os.path.join(out_dir, full_res_dir, var)\n",
    "    ds = xarray.open_dataset(file_path)\n",
    "    for i in range(ds.dims[\"time\"]):\n",
    "        # get frame at time index i\n",
    "        arr = ds[var].isel(time=i)\n",
    "\n",
    "        # make it geo\n",
    "        arr = dcug.assign_crs(arr, \"EPSG:4326\")\n",
    "\n",
    "        # extract date\n",
    "        date_str = np.datetime_as_string(arr.time, unit=\"D\")\n",
    "\n",
    "        # Write as Cloud Optimized GeoTIFF\n",
    "        write_cog(\n",
    "            geo_im=arr,\n",
    "            fname=os.path.join(out_path, f\"cruts-{var}-{date_str}.tif\"),\n",
    "            overwrite=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-matthew",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = dask.bag.from_sequence(variables).map(as_cog).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-trial",
   "metadata": {},
   "source": [
    "# Resize WorldClim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-prior",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from typing import Tuple\n",
    "\n",
    "import dask.bag\n",
    "import datacube.utils.geometry as dcug\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import xarray\n",
    "from dask.diagnostics import ProgressBar\n",
    "from datacube.utils.cog import write_cog\n",
    "from distributed import Client\n",
    "from rasterio import Affine, MemoryFile\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "pbar = ProgressBar()\n",
    "pbar.register()\n",
    "\n",
    "resolutions = [\n",
    "    (720, 360),\n",
    "    (1080, 720),\n",
    "    (2160, 1080),\n",
    "]\n",
    "\n",
    "data_dir = \"/media/xultaeculcis/2TB/datasets/wc/weather/\"\n",
    "variables = [\n",
    "    \"tmin\",\n",
    "    \"tmax\",\n",
    "    \"prec\",\n",
    "]\n",
    "\n",
    "pattern = \"*.tif\"\n",
    "\n",
    "out_dir = \"/media/xultaeculcis/2TB/datasets/wc/pre-processed/\"\n",
    "resized = \"resized\"\n",
    "tiled = \"tiled\"\n",
    "\n",
    "resolution_multipliers = [\n",
    "    (\"1x\", 1 / 12),\n",
    "    (\"2x\", 1 / 6),\n",
    "    (\"4x\", 1 / 3),\n",
    "]\n",
    "\n",
    "for var in variables:\n",
    "    for rm in resolution_multipliers:\n",
    "        os.makedirs(os.path.join(out_dir, var, resized, rm[0]), exist_ok=True)\n",
    "        os.makedirs(os.path.join(out_dir, var, tiled, rm[0]), exist_ok=True)\n",
    "\n",
    "\n",
    "def resize(\n",
    "    file_path: str,\n",
    "    var: str,\n",
    "    scaling_factor: float,\n",
    "    resolution_multiplier: str,\n",
    "    out_dir: str,\n",
    ") -> None:\n",
    "    with rasterio.open(file_path) as raster:\n",
    "\n",
    "        # resample data to target shape\n",
    "        t = raster.transform\n",
    "        transform = Affine(\n",
    "            t.a / scaling_factor, t.b, t.c, t.d, t.e / scaling_factor, t.f\n",
    "        )\n",
    "        height = int(raster.height * scaling_factor)\n",
    "        width = int(raster.width * scaling_factor)\n",
    "\n",
    "        profile = raster.profile\n",
    "        profile.update(transform=transform, driver=\"COG\", height=height, width=width)\n",
    "\n",
    "        data = raster.read(\n",
    "            out_shape=(raster.count, height, width),\n",
    "            resampling=Resampling.nearest,\n",
    "        )\n",
    "\n",
    "        fname = os.path.basename(file_path)\n",
    "        fname = os.path.join(out_dir, var, resized, resolution_multiplier, fname)\n",
    "\n",
    "        with rasterio.open(fname, \"w\", **profile) as dataset:  # Open as DatasetWriter\n",
    "            dataset.write(data)\n",
    "\n",
    "\n",
    "client = Client(n_workers=8, threads_per_worker=1)\n",
    "\n",
    "try:\n",
    "    for var in variables:\n",
    "        files = sorted(glob(os.path.join(data_dir, var, \"**\", pattern), recursive=True))\n",
    "        for multiplier, scale in resolution_multipliers:\n",
    "            dask.bag.from_sequence(files, npartitions=1000).map(\n",
    "                resize, var, scale, multiplier, out_dir\n",
    "            ).compute()\n",
    "finally:\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-mozambique",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (super-resolution)",
   "language": "python",
   "name": "pycharm-d1b00b73"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
